---
slug: Automating-frontend
title: Is frontend automation near?
authors: [rogelio]
tags:  [AI]
---

Will programming web applications be completely automated?

Though question to answer. So let's analyze it and try to formulate a good response. The idea that comes to my mind to start exploring the landscape consists in approaching a principled consideration in order to accumulate knowledge and arrive to an informed conclusion.

### Historical perspective
I'll just divide the pharagraphs for order of gradual evolution but was not a sequential process, all the advancements overlap in time, space, and industry axes.

First, Alan Turing, John Von Neumann, among others developed the foundational concepts of computing and programming. This was a highly manual job, deep *understanding* of computer's architecture was required.

Second, advances in early machine code for specific computer architectures. Team led by Maurice Wilkes developed the concept of microprogramming (https://dl.acm.org/doi/10.1145/1458043.1458047). A method of implementing the behavior of machine instructions by means of more elementary operations, with direct correspondence with the functions of the physical components of the computer. The control of instructions was hardwired, composed of circuits that corresponds with execution of each instruction. This was difficult to *modify*, expensive to *design* but fast. Microprogrammed allowed for simpler designs, easier to modify but slower than hardwired control.

Assembly language emerged as a symbolic representation of machine code instructions. Instead of seeing addresses of instructions, programmers saw *abstract* symbols for instructions like read from memory, store into register rsp, etc.. This was easier to *understand*, *modify* and *maintain* as compared to raw machine code. Still, it was architecture instruction set dependent.

Then, the emergence of higher-level programming languages. With all the widely known advantages in *portability*, *understanding*, *maintainability*, among others. For what I know, assembly is possible only used for critical performance, systems programming, operating system development and embedded systems nowadays. 

### 
Now, is very general, because for what I know, changes happened gradually and at different phases in different industries and at different scales.  

[Great article for scenario planning for an AGI future](https://www.imf.org/en/Publications/fandd/issues/2023/12/Scenario-Planning-for-an-AGI-future-Anton-korinek)

([The Impact of AI on Developer Productivity: Evidence from GitHub Copilot ](https://arxiv.org/abs/2302.06590))

[Technological Unemployment](https://static1.squarespace.com/static/57d002e01b631bc215df193b/t/6149b24140c1c1764ed27707/1632219713790/Susskind%2C+Handbook%2C+Updated%2C+21+September+2021+.pdf)





